# MySQL 备份恢复测试脚本注意事项

本文档总结了在编写和调试 `test.sh` 和 `test2.sh` 过程中发现的关键问题和解决方案，为后续编写类似的备份恢复测试脚本提供参考。

## 目录

1. [时区处理问题](#时区处理问题)
2. [二进制日志格式处理](#二进制日志格式处理)
3. [Docker 卷映射和目录清理](#docker-卷映射和目录清理)
4. [DDL 和 DML 分离应用](#ddl-和-dml-分离应用)
5. [Shell 转义和兼容性](#shell-转义和兼容性)
6. [时间戳精度和边界处理](#时间戳精度和边界处理)
7. [数据验证策略](#数据验证策略)
8. [错误处理和日志记录](#错误处理和日志记录)

---

## 1. 时区处理问题

### 问题描述

**核心问题**：`mysqlbinlog` 的 `--stop-datetime` 参数使用时区不一致，导致数据恢复不准确。

**具体表现**：
- 在 `test2.sh` 中，即使记录了目标时间点，恢复后的数据仍然包含目标时间点之后的操作
- MD5 校验失败，发现恢复后的数据比预期多了几条记录
- 时区转换导致 8 小时的时间差（UTC vs Asia/Shanghai）

### 根本原因

1. **时区不一致**：
   - MySQL 服务器配置为 `Asia/Shanghai` (UTC+8)
   - `mysqlbinlog` 的 `--stop-datetime` 参数默认使用系统时区
   - 如果系统时区是 UTC，而目标时间是 `Asia/Shanghai`，会导致 8 小时偏差

2. **时间戳转换不准确**：
   - 使用 `date -d` 进行时区转换时，如果环境变量 `TZ` 未正确设置，转换结果可能不准确
   - 字符串时间格式在不同时区下的解析可能产生歧义

### 解决方案

#### 方案 1：统一使用 UTC 时间戳（推荐）

```bash
# 记录快照时，同时记录 epoch 时间戳
PITR_TARGET_TIME=$(TZ="$TZ_REGION" date '+%Y-%m-%d %H:%M:%S')
PITR_TARGET_EPOCH=$(TZ="$TZ_REGION" date -d "$PITR_TARGET_TIME" +%s)

# 应用 binlog 时，将 epoch 转换为 UTC 时间字符串
stop_timestamp=$((PITR_TARGET_EPOCH + 1))
stop_datetime_utc=$(TZ=UTC date -d "@$stop_timestamp" "+%Y-%m-%d %H:%M:%S")

# 使用 UTC 时间调用 mysqlbinlog
mysqlbinlog --stop-datetime="$stop_datetime_utc" ...
```

**优点**：
- 不依赖系统时区设置
- 时间戳是绝对时间，转换准确
- 跨时区环境也能正常工作

#### 方案 2：确保时区环境变量一致

```bash
# 在脚本开始时设置时区
export TZ='Asia/Shanghai'

# 在 docker exec 中也要设置
docker exec -e TZ='Asia/Shanghai' "$CONTAINER_NAME" bash -c '
  export TZ="Asia/Shanghai"
  mysqlbinlog --stop-datetime="$TARGET_TIME" ...
'
```

**注意事项**：
- 需要确保所有相关进程都使用相同的时区
- Docker 容器内的时区可能不同，需要显式设置

### 最佳实践

1. **同时记录本地时间和 epoch**：
   ```bash
   PITR_TARGET_TIME=$(TZ="$TZ_REGION" date '+%Y-%m-%d %H:%M:%S')
   PITR_TARGET_EPOCH=$(TZ="$TZ_REGION" date -d "$PITR_TARGET_TIME" +%s)
   ```

2. **使用 epoch 进行 UTC 转换**：
   ```bash
   stop_datetime_utc=$(TZ=UTC date -d "@$PITR_TARGET_EPOCH" "+%Y-%m-%d %H:%M:%S")
   ```

3. **在恢复脚本中接收时区参数**：
   ```bash
   RESTORE_TZ=${RESTORE_TZ:-Asia/Shanghai}
   export TZ="$RESTORE_TZ"
   ```

---

## 2. 二进制日志格式处理

### 问题描述

**核心问题**：ROW 格式的二进制日志不能直接作为 SQL 执行，需要特殊处理。

**具体表现**：
- `mysqlbinlog` 输出的 ROW 格式日志包含 `BINLOG '...'` 语句
- 直接通过 `mysql` 客户端执行时，可能报错或数据未插入
- `--base64-output=DECODE-ROWS --verbose` 输出的是伪 SQL（以 `###` 开头），不能直接执行

### 根本原因

1. **ROW 格式的特点**：
   - ROW 格式记录的是行的变化，而不是 SQL 语句
   - 需要通过 `BINLOG` 语句来应用，这需要 MySQL 服务器支持
   - 伪 SQL 输出（`###` 开头）是用于人类阅读的，不是可执行的 SQL

2. **MySQL 客户端限制**：
   - 普通 `mysql` 客户端可能无法正确处理 `BINLOG` 语句
   - 需要使用 `--binary-mode` 或 `PSEUDO_REPLICA_MODE` 等特殊模式

### 解决方案

#### 方案 1：直接使用 mysqlbinlog 输出（推荐）

```bash
# 对于 ROW 格式，mysqlbinlog 的输出可以直接通过 mysql 客户端应用
mysqlbinlog --stop-datetime="$stop_datetime_utc" --skip-gtids --database="$MYSQL_DB" "$binlog_file" | \
  mysql --binary-mode=1 -h 127.0.0.1 -u root -p"$MYSQL_PWD" "$MYSQL_DB"
```

**注意事项**：
- 需要 `--binary-mode=1` 或 `--binary-mode` 参数
- 确保 MySQL 服务器支持 `BINLOG` 语句

#### 方案 2：转换为可执行的 INSERT 语句

```bash
# 使用 --base64-output=DECODE-ROWS --verbose 获取伪 SQL
# 然后使用 awk 脚本转换为真正的 INSERT 语句
mysqlbinlog --base64-output=DECODE-ROWS --verbose "$binlog_file" | \
  awk '
  BEGIN { flag=0; vals=""; current_db=""; current_table="" }
  /^### INSERT INTO/ {
      split($0, parts, "\140")  # \140 是反引号的八进制表示
      current_db = parts[2]
      current_table = parts[4]
      flag=1
      vals=""
      next
  }
  flag && /^###   @[0-9]+=/ {
      # 提取列值
      gsub(/^###[[:space:]]+@[0-9]+=/, "")
      gsub(/^[[:space:]]+/, "")
      gsub(/[[:space:]]+$/, "")
      if(vals=="") { vals=$0 } else { vals=vals", " $0 }
      next
  }
  flag && /^# at [0-9]+$/ {
      if(vals!="" && current_table!="") {
          print "INSERT INTO " current_db "." current_table " VALUES (" vals ");"
      }
      flag=0
      vals=""
  }' | \
  mysql -h 127.0.0.1 -u root -p"$MYSQL_PWD" "$MYSQL_DB"
```

**适用场景**：
- 需要调试或查看具体的 SQL 语句
- 需要处理特殊的数据类型转换（如时间戳）

### 最佳实践

1. **优先使用方案 1**（直接应用 binlog），性能更好，兼容性更强

2. **如果需要转换，注意以下问题**：
   - Shell 转义：反引号需要使用八进制 `\140` 或 `split` 函数
   - 列顺序：`INSERT INTO table VALUES (...)` 依赖列顺序，需要确保顺序正确
   - 数据类型：时间戳等特殊类型可能需要 `FROM_UNIXTIME()` 转换

3. **测试不同格式**：
   - 在 `docker-compose.yml` 中明确设置 `--binlog-format=ROW`
   - 测试脚本应该能够处理 ROW 格式

---

## 3. Docker 卷映射和目录清理

### 问题描述

**核心问题**：清理测试环境时，如果删除整个目录，Docker 卷映射会失效。

**具体表现**：
- 执行 `rm -rf ./mysql_data` 后，重新启动容器时，卷映射可能不生效
- 容器内无法访问预期的目录
- 备份文件找不到，因为目录被完全删除

### 根本原因

1. **Docker 卷映射机制**：
   - Docker 在启动时，如果挂载点不存在，会创建一个目录
   - 如果挂载点已存在但为空，Docker 会使用该目录
   - 如果挂载点被完全删除，Docker 会重新创建，但可能丢失权限或配置

2. **目录权限问题**：
   - 删除目录后重新创建，可能权限不正确
   - MySQL 需要特定的目录权限（通常是 `mysql:mysql` 和 `700`）

### 解决方案

```bash
# ❌ 错误做法：删除整个目录
rm -rf ./mysql_data ./backups ./mysql_config

# ✅ 正确做法：只删除目录内容，保留目录结构
rm -rf ./mysql_data/* ./mysql_data/.[!.]* ./mysql_data/..?* 2>/dev/null || true
rm -rf ./backups/* ./backups/.[!.]* ./backups/..?* 2>/dev/null || true
rm -rf ./mysql_config/* ./mysql_config/.[!.]* ./mysql_config/..?* 2>/dev/null || true

# 如果目录不存在，创建它
mkdir -p ./mysql_data ./backups ./mysql_config
```

**解释**：
- `./mysql_data/*`：删除所有可见文件
- `./mysql_data/.[!.]*`：删除以 `.` 开头的文件（排除 `.` 和 `..`）
- `./mysql_data/..?*`：删除以 `..` 开头的文件
- `2>/dev/null || true`：忽略错误，确保脚本继续执行

### 最佳实践

1. **清理函数模板**：
   ```bash
   cleanup() {
       local dirs=("mysql_data" "backups" "mysql_config")
       for dir in "${dirs[@]}"; do
           if [ -d "./$dir" ]; then
               rm -rf "./$dir"/* "./$dir"/.[!.]* "./$dir"/..?* 2>/dev/null || true
           else
               mkdir -p "./$dir"
           fi
       done
   }
   ```

2. **权限设置**：
   ```bash
   # 确保目录权限正确
   chmod 755 ./mysql_data ./backups ./mysql_config
   ```

---

## 4. DDL 和 DML 分离应用

### 问题描述

**核心问题**：在应用二进制日志时，需要先应用 DDL（如 `CREATE TABLE`），再应用 DML（如 `INSERT`）。

**具体表现**：
- 直接应用包含 `INSERT` 的 binlog 时，报错 `Table 'testdb.timestamp_test' doesn't exist`
- 即使 binlog 中包含 `CREATE TABLE` 语句，也可能因为顺序问题导致表不存在

### 根本原因

1. **binlog 事件顺序**：
   - `CREATE TABLE` 和 `INSERT` 可能在不同的 binlog 文件中
   - `mysqlbinlog` 按文件顺序输出，可能先输出 `INSERT`，后输出 `CREATE TABLE`

2. **多行 DDL 语句**：
   - `CREATE TABLE` 语句可能跨越多行
   - 简单的 `grep` 可能无法完整提取

### 解决方案

```bash
# 步骤 1：先提取并应用所有 DDL 语句
mysqlbinlog --stop-datetime="$stop_datetime" --skip-gtids --database=testdb "$binlog_file" 2>/dev/null | \
  awk '/CREATE TABLE IF NOT EXISTS/,/ENGINE=InnoDB/ {print} /ENGINE=InnoDB/ {print "/*!*/;"}' | \
  mysql -h 127.0.0.1 -u root -p"$MYSQL_ROOT_PASSWORD" testdb 2>&1 | grep -E "ERROR|Warning" || true

# 步骤 2：再应用 DML 语句（INSERT/UPDATE/DELETE）
mysqlbinlog --stop-datetime="$stop_datetime" --skip-gtids --database=testdb "$binlog_file" 2>/dev/null | \
  mysql --binary-mode=1 -h 127.0.0.1 -u root -p"$MYSQL_ROOT_PASSWORD" testdb
```

**注意事项**：
- DDL 提取需要处理多行语句
- 可以使用 `awk` 的范围模式 `/pattern1/,/pattern2/` 来匹配多行
- 确保 DDL 应用成功后再应用 DML

### 最佳实践

1. **两阶段应用**：
   - 第一阶段：提取并应用所有 DDL
   - 第二阶段：应用所有 DML

2. **错误处理**：
   ```bash
   # 检查 DDL 应用是否成功
   ddl_errors=$(mysql ... < ddl.sql 2>&1 | grep -i error | wc -l)
   if [ "$ddl_errors" -gt 0 ]; then
       log_error "DDL 应用失败"
       exit 1
   fi
   ```

---

## 5. Shell 转义和兼容性

### 问题描述

**核心问题**：在 `docker exec` 中执行复杂的 shell 脚本时，特殊字符转义容易出错。

**具体表现**：
- 反引号（`` ` ``）在 shell 字符串中需要特殊处理
- 正则表达式中的特殊字符可能导致语法错误
- `sh` 和 `bash` 的语法差异（如 `[[ ]]` vs `[ ]`）

### 根本原因

1. **Shell 嵌套**：
   - `docker exec ... bash -c '...'` 中的单引号字符串需要转义
   - 多层引号嵌套容易出错

2. **字符编码**：
   - 反引号在某些编码下可能显示异常
   - 使用八进制或十六进制表示更安全

### 解决方案

#### 方案 1：使用八进制表示特殊字符

```bash
# ❌ 错误：反引号在 shell 中有特殊含义
awk '/^### INSERT INTO `db`.`table`/ { ... }'

# ✅ 正确：使用八进制表示
awk '/^### INSERT INTO \140db\140.\140table\140/ { ... }'
# \140 是反引号的八进制 ASCII 码（96）
```

#### 方案 2：使用 split 函数

```bash
# ✅ 更安全：使用 split 函数解析
awk '
  /^### INSERT INTO/ {
      split($0, parts, "\140")  # 按反引号分割
      current_db = parts[2]
      current_table = parts[4]
      ...
  }
'
```

#### 方案 3：使用临时文件

```bash
# 将复杂的 awk 脚本写入临时文件
cat > /tmp/convert_binlog.awk <<'AWK_SCRIPT'
BEGIN { ... }
/^### INSERT INTO/ { ... }
AWK_SCRIPT

# 然后使用临时文件
mysqlbinlog ... | awk -f /tmp/convert_binlog.awk
```

### 最佳实践

1. **避免在 docker exec 中嵌套复杂脚本**：
   - 将复杂逻辑提取到独立的脚本文件
   - 通过卷映射将脚本文件挂载到容器中

2. **使用 `case` 代替 `[[ ]]`**（提高兼容性）：
   ```bash
   # ❌ bash 特有
   if [[ "$var" == "value" ]]; then
   
   # ✅ sh 兼容
   case "$var" in
     "value") ... ;;
   esac
   ```

3. **测试不同 shell**：
   - 在 `docker exec` 中明确指定 `bash` 或 `sh`
   - 测试脚本在不同 shell 下的行为

---

## 6. 时间戳精度和边界处理

### 问题描述

**核心问题**：`mysqlbinlog --stop-datetime` 是排他性的，可能遗漏边界时间点的数据。

**具体表现**：
- 目标时间是 `2025-11-27 18:08:43`，但恢复后缺少该时间点的最后一条记录
- 即使时间点精确到秒，仍可能遗漏数据

### 根本原因

1. **排他性边界**：
   - `--stop-datetime` 会在第一个时间**等于或晚于**参数的事件处停止
   - 这意味着等于目标时间的事件可能被排除

2. **时间精度**：
   - binlog 中的时间戳精度可能到微秒
   - 字符串时间格式只精确到秒

### 解决方案

```bash
# ✅ 将目标时间加 1 秒，确保包含目标时间点的所有数据
stop_timestamp=$((PITR_TARGET_EPOCH + 1))
stop_datetime_utc=$(TZ=UTC date -d "@$stop_timestamp" "+%Y-%m-%d %H:%M:%S")

mysqlbinlog --stop-datetime="$stop_datetime_utc" ...
```

**注意事项**：
- 加 1 秒可能会包含目标时间点之后 1 秒内的数据
- 如果 binlog 中有 `Delete_rows` 事件，需要额外过滤（见下一节）

### 最佳实践

1. **记录精确的时间戳**：
   ```bash
   # 记录到微秒（如果可能）
   PITR_TARGET_TIME=$(date '+%Y-%m-%d %H:%M:%S.%N')
   PITR_TARGET_EPOCH=$(date -d "$PITR_TARGET_TIME" +%s)
   ```

2. **验证边界数据**：
   - 在测试中，验证目标时间点的数据是否被正确包含
   - 验证目标时间点之后的数据是否被正确排除

---

## 7. Delete_rows 事件过滤

### 问题描述

**核心问题**：如果 binlog 中包含 `Delete_rows` 事件（模拟误操作），需要过滤掉这些事件。

**具体表现**：
- 恢复后的数据比预期少
- 某些记录在恢复过程中被删除

### 根本原因

1. **误操作模拟**：
   - 测试脚本会模拟误操作（删除数据）
   - 这些删除操作会记录在 binlog 中
   - 如果直接应用整个 binlog，会执行这些删除操作

2. **时间点判断**：
   - `Delete_rows` 事件可能就在目标时间点之后
   - 需要精确截断到目标时间点

### 解决方案

```bash
# 提取 binlog 到临时文件
temp_binlog=$(mktemp)
mysqlbinlog --stop-datetime="$stop_datetime" "$binlog_file" > "$temp_binlog"

# 检查是否包含 Delete_rows 事件
delete_rows_count=$(grep -c "Delete_rows" "$temp_binlog" 2>/dev/null | tr -d '\r\n' || echo "0")

if [ "$delete_rows_count" -gt 0 ]; then
    # 找到第一个 Delete_rows 事件的位置
    delete_rows_line=$(grep -n "Delete_rows" "$temp_binlog" | head -1 | cut -d: -f1)
    
    # 找到 Delete_rows 之前的最后一个 COMMIT
    last_commit_line=$(head -n $((delete_rows_line - 1)) "$temp_binlog" | grep -n "COMMIT" | tail -1 | cut -d: -f1)
    
    if [ -n "$last_commit_line" ]; then
        # 截断到最后一个 COMMIT
        head -n "$last_commit_line" "$temp_binlog" > "${temp_binlog}.tmp"
        mv "${temp_binlog}.tmp" "$temp_binlog"
    fi
fi

# 应用处理后的 binlog
cat "$temp_binlog" | mysql ...
```

### 最佳实践

1. **在测试脚本中记录 binlog 位置**：
   ```bash
   # 在模拟误操作之前记录 binlog 位置
   record_binlog_position
   ```

2. **使用 binlog 位置而不是时间**（如果可能）：
   ```bash
   # 更精确：使用位置而不是时间
   mysqlbinlog --start-position="$start_pos" --stop-position="$target_pos" ...
   ```

---

## 8. 数据验证策略

### 问题描述

**核心问题**：如何可靠地验证恢复后的数据是否正确。

**具体表现**：
- 简单的行数比较可能不够
- 时间戳字段可能导致 MD5 不一致（即使数据相同）

### 解决方案

#### 方案 1：MD5 校验（推荐）

```bash
# 导出数据快照（只包含数据，不包含时间戳等可能变化的字段）
dump_all_tables() {
    local output_file="$1"
    >"$output_file"
    for table in "${TABLES[@]}"; do
        {
            echo "TABLE:${table}"
            # 使用 ORDER BY 确保顺序一致
            docker exec "$CONTAINER_NAME" mysql -h 127.0.0.1 -u root -p"${MYSQL_ROOT_PASSWORD}" \
                --batch --skip-column-names "${MYSQL_DATABASE}" \
                -e "SELECT * FROM ${table} ORDER BY 1;" | sed 's/\t/|/g'
        } >>"$output_file"
    done
}

# 计算 MD5
compute_md5() {
    local file="$1"
    md5sum "$file" | awk '{print $1}'
}

# 比较
if [ "$BASELINE_MD5" == "$RESTORED_MD5" ]; then
    log_success "数据恢复成功"
else
    log_error "数据恢复失败"
    # 显示差异
    diff -u "$DATA_SNAPSHOT_BEFORE" "$DATA_SNAPSHOT_AFTER"
fi
```

**注意事项**：
- 使用 `ORDER BY` 确保数据顺序一致
- 排除可能变化的字段（如 `updated_at` 时间戳）
- 使用 `--batch --skip-column-names` 确保输出格式一致

#### 方案 2：逐表逐行比较

```bash
# 更详细的比较
for table in "${TABLES[@]}"; do
    before_count=$(mysql ... -e "SELECT COUNT(*) FROM ${table}" | tail -1)
    after_count=$(mysql ... -e "SELECT COUNT(*) FROM ${table}" | tail -1)
    
    if [ "$before_count" != "$after_count" ]; then
        log_error "表 ${table} 行数不一致: 恢复前=$before_count, 恢复后=$after_count"
    fi
done
```

### 最佳实践

1. **快照格式**：
   - 使用固定的分隔符（如 `|`）
   - 排除自动更新的字段（如 `updated_at`）
   - 使用 `ORDER BY` 确保顺序

2. **保存快照文件**：
   - 保存恢复前后的快照文件，便于调试
   - 使用时间戳命名，避免覆盖

3. **详细日志**：
   - 记录每个表的行数
   - 记录 MD5 值
   - 如果失败，显示差异

---

## 9. 错误处理和日志记录

### 问题描述

**核心问题**：测试脚本需要详细的日志和错误处理，便于调试。

### 解决方案

```bash
# 日志函数
log_info() { echo -e "${BLUE}[INFO]${NC} $*"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $*"; }
log_error() { echo -e "${RED}[ERROR]${NC} $*"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $*"; }

# 错误计数
ERROR_COUNT=0
WARNING_COUNT=0

# 错误处理
set -euo pipefail
trap 'handle_error $LINENO "$BASH_COMMAND"' ERR

handle_error() {
    local line=$1
    local command=$2
    log_error "脚本在第 $line 行执行命令时出错: $command"
    exit 1
}

# 步骤标记
log_step() {
    echo ""
    echo -e "${GREEN}========================================${NC}"
    echo -e "${GREEN}$*${NC}"
    echo -e "${GREEN}========================================${NC}"
    echo ""
}
```

### 最佳实践

1. **使用 `set -euo pipefail`**：
   - `-e`：遇到错误立即退出
   - `-u`：使用未定义变量时报错
   - `-o pipefail`：管道中任何命令失败都视为失败

2. **记录关键信息**：
   - 时间点、binlog 位置、MD5 值等
   - 保存到文件，便于后续分析

3. **错误恢复**：
   - 对于可预期的错误（如文件不存在），使用 `|| true` 忽略
   - 对于关键错误，立即退出并显示详细信息

---

## 10. 总结和建议

### 关键要点

1. **时区处理**：始终使用 UTC 时间戳进行转换，避免时区偏差
2. **binlog 格式**：明确使用 ROW 格式，并正确处理 `BINLOG` 语句
3. **目录清理**：只删除内容，不删除目录本身
4. **DDL/DML 分离**：先应用 DDL，再应用 DML
5. **Shell 兼容性**：避免使用 bash 特有语法，使用八进制表示特殊字符
6. **边界处理**：目标时间加 1 秒，确保包含边界数据
7. **数据验证**：使用 MD5 校验，确保数据完整性

### 测试脚本模板

```bash
#!/bin/bash
set -euo pipefail

# 1. 配置变量
TZ_REGION="Asia/Shanghai"
export TZ="$TZ_REGION"

# 2. 清理环境（只删除内容）
cleanup() {
    rm -rf ./mysql_data/* ./mysql_data/.[!.]* ./mysql_data/..?* 2>/dev/null || true
    mkdir -p ./mysql_data
}

# 3. 记录时间点（同时记录本地时间和 epoch）
record_snapshot() {
    PITR_TARGET_TIME=$(TZ="$TZ_REGION" date '+%Y-%m-%d %H:%M:%S')
    PITR_TARGET_EPOCH=$(TZ="$TZ_REGION" date -d "$PITR_TARGET_TIME" +%s)
}

# 4. 应用 binlog（使用 UTC 时间）
apply_binlog() {
    stop_timestamp=$((PITR_TARGET_EPOCH + 1))
    stop_datetime_utc=$(TZ=UTC date -d "@$stop_timestamp" "+%Y-%m-%d %H:%M:%S")
    mysqlbinlog --stop-datetime="$stop_datetime_utc" ... | mysql --binary-mode=1 ...
}

# 5. 验证数据（MD5 比较）
verify_restore() {
    dump_all_tables "$SNAPSHOT_AFTER"
    RESTORED_MD5=$(md5sum "$SNAPSHOT_AFTER" | awk '{print $1}')
    if [ "$BASELINE_MD5" == "$RESTORED_MD5" ]; then
        log_success "恢复成功"
    else
        log_error "恢复失败"
        exit 1
    fi
}
```

---

## 附录：常见错误和快速排查

| 错误信息 | 可能原因 | 解决方法 |
|---------|---------|---------|
| `Table doesn't exist` | DDL 未应用 | 先应用 DDL，再应用 DML |
| MD5 不一致 | 时区问题或边界数据 | 使用 UTC 时间戳，目标时间加 1 秒 |
| `syntax error near unexpected token` | Shell 转义问题 | 使用八进制表示特殊字符 |
| 数据比预期少 | Delete_rows 事件 | 过滤 Delete_rows 事件 |
| 数据比预期多 | 时间边界问题 | 检查 `--stop-datetime` 是否正确 |
| 卷映射失效 | 目录被删除 | 只删除目录内容，不删除目录 |

---

**最后更新**：2025-11-27  
**维护者**：根据 `test.sh` 和 `test2.sh` 的调试经验总结

